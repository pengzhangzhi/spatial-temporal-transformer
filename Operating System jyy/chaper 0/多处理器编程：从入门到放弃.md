## Introduction：

**多线程编程有什么难的？**

要回答这个问题，不如先写一个多线程程序亲身体验一下。

在这篇文章中，我们使用C编写一个简单的多线程程序并观察它的行为。

## 线程库：

假设你有以下代码，命名为 `threads.h`：

```
#include <stdlib.h>
#include <stdio.h>
#include <assert.h>
#include <pthread.h>

struct thread {
  int id;
  pthread_t thread;
  void (*entry)(int);
  struct thread *next;
};

struct thread *threads;
void (*join_fn)();

// ========== Basics ==========

__attribute__((destructor)) static void join_all() {
  for (struct thread *next; threads; threads = next) {
    pthread_join(threads->thread, NULL);
    next = threads->next;
    free(threads);
  }
  join_fn ? join_fn() : (void)0;
}

static inline void *entry_all(void *arg) {
  struct thread *thread = (struct thread *)arg;
  thread->entry(thread->id);
  return NULL;
}

static inline void create(void *fn) {
  struct thread *cur = (struct thread *)malloc(sizeof(struct thread));
  assert(cur);
  cur->id    = threads ? threads->id + 1 : 1;
  cur->next  = threads;
  cur->entry = (void (*)(int))fn;
  threads    = cur;
  pthread_create(&cur->thread, NULL, entry_all, cur);
}

static inline void join(void (*fn)()) {
  join_fn = fn;
}

// ========== Synchronization ==========

#include <stdint.h>

intptr_t atomic_xchg(volatile intptr_t *addr,
                               intptr_t newval) {
  // swap(*addr, newval);
  intptr_t result;
  asm volatile ("lock xchg %0, %1":
    "+m"(*addr), "=a"(result) : "1"(newval) : "cc");
  return result;
}

intptr_t locked = 0;

static inline void lock() {
  while (1) {
    intptr_t value = atomic_xchg(&locked, 1);
    if (value == 0) {
      break;
    }
  }
}

static inline void unlock() {
  atomic_xchg(&locked, 0);
}

#include <semaphore.h>

#define P sem_wait
#define V sem_post
#define SEM_INIT(sem, val) sem_init(&(sem), 0, val)

```

### 线程的数据结构是一个链表：

```
struct thread {
  int id;               // 从 1 开始的线程号
  pthread_t thread;     // pthreads 线程号
  void (*entry)(int);   // 线程的入口函数
  struct thread *next;  // 链表
};
```

### 线程创建：

```
void create(void *fn) {
  struct thread *cur = (struct thread *)malloc(sizeof(struct thread));
  assert(cur);
  cur->id    = threads ? threads->id + 1 : 1;
  cur->next  = threads;
  cur->entry = (void (*)(int))fn;
  threads    = cur;
  pthread_create(&cur->thread, NULL, entry_all, cur);
}
```

### Join：

等待所有线程结束

```
void join(void (*fn)()) {
  join_fn = fn;
}
```

### 第一段多线程代码：

```
#include <threads.h>

void f(){
static x = 0;
printf("hello thread: %d",x++);
while(1);
} // 多线程函数程序

int main(){
for (int i =0; i < 1000;i ++){ //开启1000个多线程
create(f); //为每个函数创建函数
}
join(NULL); // 等待所有线程结束

}
```

结果当然是百花齐放，打印的x并不是按顺序从0-1000，可能是0 6 66 55 14 25 .....

你会发现：

- 多线程是并发调用的，不然按顺序运行只会出现死循环。
- x是贡献的，不同线程打印不同数字。

### 并发编程的难题

上面我们发现多个线程是共享内存的，因此对共享变量的访问会产生竞争（race）。

多个线程共享内存，因此对共享变量的访问就会形成 “竞争” (races)，例如以下这个例子是两个线程求 1+1+…+1 (2n 个 1)：

```
#define n 100000000
long sum = 0;
void do_sum() {
  for (int i = 0; i < n; i++) sum++;
}
void print() {
  printf("sum = %ld\n", sum);
}
int main() {
  create(do_sum);
  create(do_sum);
  join(print);
}
```

执行结果：

- `gcc -O0` (8.726s) sum = 1054212206
- `gcc -O1` (0.388s) sum = 1000000000
- `gcc -O2` (0.002s) sum = 2000000000

不同编译方式竟然结果完全不同，为什么。。

### Case 1：

`sum++` 实际运行时会被分割为以下三条指令

```
tmp = sum;
tmp += 1;
sum = tmp;
```

假设sum = 0， t1 t2两个线程同时访问sum，会出现以下结果：

```
t1                   		 		t2

tmp = sum // 0					

									tmp = sum // 0

tmp += 1

sum = tmp // 1			

								tmp += 1

								sum = tmp // 1 
```

因此你会发现最后打印的数字很奇怪。

而 -o1, -o2 是编译器优化选项，

`-o1` 直到while结束再将tmp赋值给sum，而 o2直接将循环优化成sum+=n。

```
void do_sum() {
  long tmp = sum;
  if (is_O1) {
    for (int i = 0; i < n; i++) ;
  }
  if (is_O2) {
  }
  tmp += n;
  sum = tmp;
}
```

由于o1 read and write之间间隔很长，因此数值总是被覆盖，结果是1000 而 o2 的read and write 几乎紧接着发生（由于CPU时钟周期只有1纳秒），因此出现了正确的结果，但理论上任由极低的概率出现read和write同步现象，出现o1的错误。不行各位可以试试。

**在共享内存中，语句的执行并不严格按照编写的顺序发生**。语句的原子性丧失了！

### 编译器：顺序的丧失

在编译优化如此成熟的现在，你写的顺序代码几乎会被编译器做不同程度的魔改，真正运行的代码几乎不会和你原来的代码一致。

在这里，我们用一个简化的模型来揭示一下编译优化做了什么，即考虑一个顺序程序只做读内存、写内存和局部本地的计算。

```
[1] t1 = R(x)
 ->     t1 = t1 + 1
 -> [2] W(x, t1)
 -> [3] t2 = R(x)
 ->     t2 = t2 * 2
 -> [4] W(x, t2)
 -> [5] t2 = R(y)
```

首先考虑 `[2] -> [3]`。容易发现，我们读出的变量，恰好是刚才写入的变量，即对于顺序程序，在 `[3]` 结束时，我们能证明 t2=t1。换句话说，我们可以把读操作删除，改写成一个本地的计算：

```
    [1] t1 = R(x)
 ->     t1 = t1 + 1
 -> [2] W(x, t1)
 ->     t1 = t1 * 2
 -> [4] W(x, t1)
 -> [5] t2 = R(y)
```

再考虑 `[2] -> [4]`，连续的两次对 `x` 的写操作，后一次会覆盖前一次的数值。从顺序执行程序的意义上，把 `[2]` 删除也不会有任何影响：

```
    [1] t1 = R(x)
 ->     t1 = t1 + 1
 ->     t1 = t1 * 2
 -> [4] W(x, t1)
 -> [5] t2 = R(y)
```

此外，如果 `x` 和 `y` 不是同一个变量 (实际的情况可能复杂一些，例如 `x` 和 `y` 可能是由 pointer dereference 得到的，判定它们是否是同一个变量属于 “指针分析” 这一难题)，编译器可能出于性能的考虑，交换 `[5]` 和 `[4]`，得到在处理器意义上可能运行得更快的代码：

```
    [1] t1 = R(x)
 -> [5] t2 = R(y) // 使内存访问提前，减少 cache miss 对后续指令的影响
 ->     t1 = t1 + 1
 ->     t1 = t1 * 2
 -> [4] W(x, t1)
```

可见，一小段代码已经被优化得完全面目全非了——之前的求和函数不同优化的结果都是合理的，以下都是求和函数在顺序意义上等价的表示：

```
// 不优化的时候几乎是一个 “忠于 C 代码” 的直接翻译。
void f_O0() {
  for (int i = 0; i < N; i++) {
    int t = R(sum);
    t++;
    W(sum, t);
  }
}
```

### 多核处理器：可见性的丧失

现在的CPU速度已经达到milisecond, 因此影响程序运行效率的主要因素的IO。 为了解决这个问题，现代计算机一般都使用cache来提高访存的效率。 

当cache miss的时候，CPU不会坐以待毙，等待数据从内存中读取（这个时间相对于CPU时钟周期相当慢！），而是立即去执行下一条指令。 这样的优化即使cache miss也不会降低CPU的吞吐率。保证的计算机的高效运行。

但这样乱序的执行会导致read / write的顺序发生改变。不同处理器不可见其他处理器的操作，造成无法预测的结果。 

**在多线程共享内存时，并发程序的行为无法准确建模。**

## 结束语：原子性，顺序，可见性都丧失了，我们还编个锤子？

如果我们的多线程程序真有上述的问题，那自己编的程序结果可能还没有随机生成的结果准确，XD

当然，这种担心是多余的，计算机系统为我们提供了一些列的技术帮助我们写出正确的多线程代码。

> 为了解决并发编程这个老大难问题，计算机系统为我们提供了同时保证顺序、原子性、可见性的同步操作——互斥锁、条件变量、信号量、事务内存……帮助程序员写出正确性容易保证的代码、实现并发控制。

